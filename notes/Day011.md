# Day 11
`code/011_leaky_relu.cu`

## Atomics
- For CUDA kernels to be performant, parallelism is the key. And for which, each thread must be able to operate independently. 
- But, there's exists way for threads in same block to access same shared memory. And this can result in race conditions. 
- There is block wise synchronization with `__syncthreads()`. But, cuda doesn't provide a way for blocks across grids to synchronize. 
- There is a way to provide synchronous access to global memory. A thread obtains lock, read-modify-write in global memory and then releases it. 
- Atomic functions should be used sparingly as they enforce thread synchronization and can affect performance. 
- CUDA provides atomics with same behaviour as cpp, as `cuda::std::atomic` and `cuda::std::atomic_ref`. It also allows `cuda::atomic` and `cuda::atomic_ref` to specify the thread scope of the atomic operation. 

Eg: A global location `result` is being used to store the sum by all threads. 
```cpp

__global__ void sumReduction(int n, float* array, float* result){
    tid = threadIdx.x + blockIdx.x * blockDim.x;
    cuda::atomic_ref<float, cuda::thread_scope_device>, result_ref(result);
    result_ref.fetch_add(array[tid]);
}
```


## Cooperative Groups
- Cuda programming model allows threads within a thread block or thread clusters to synchronize efficiently. 
- But, doesn't provide a mechanism for specifying thread groups smaller than a thread block or cluster. Also, doesn't allow synchronization across thread blocks. 
- Cooperative groups is a software tool, that enables synchronization between groups of threads, spanning multiple blocks, grids on a single GPU or even across multiple GPUs. 
- Creating thread groups to enable such synchronization comes with limitations and performance implications. 


## Kernel Launch and Occupancy
- Using execution configuration we can determine the number blocks per grid and threads per block. Based on this, during kernel launch CUDA threads are grouped into blocks and grids. Which blocks are scheduled to be executed on which SM can't be controlled, scheduler does it by itself. 
- When a kernel launches, the scheduler assings thread blocks to SMs. As long as SMs have enough resources, the scheduler will continue assigning thread blocks to SM. If resource is not available, scheduler waits for other SMs to finish previous thread blocks and assigns others until all thread blocks are executed. 
- The occupancy of a CUDA kernel is the number of active warps to the maximum number of active warps supported by the SM. A high occupancy is more performant. 
- 
## Calculating Occupancy
To calculate occupancy of a Kernel, the resources of the SM must be understood. 
1. `maxBlocksPerMultiProcessor`: The maximum number of resident blocks per SM. 
2. `sharedMemMultiProcessor`: The amount of shared memory available per SM in bytes. 
3. `regsPerMultiProcessor`: The number of 32-bit registers available per SM. 
4. `maxThreadsPerMultiProcessor`: Max number of resident threads per SM. 
5. `sharedMemBlock`: Max amount of shared memory that can be allocated by a thread block in bytes. 
6. `regsPerBlock`: Max number of 32-bit registers that can be allocated by a thread block. 
7. `maxThreadsPerBlock`: Max number of threads per thread block. 

---

Eg: 
Let's say, our SM has following resources: 
- `maxBlocksPerMultiProcessor` : 32
- `sharedMemPerMultiprocessor` : 233472
- `regsPerMultiprocessor` : 65536
- `maxThreadsPerMultiProcessor`: 2048
- `sharedMemPerBlock` : 49152
- `regsPerBlock` : 65536
- `maxThreadsPerBlock` : 1024

Here, if a kernel was launched with `testkernel<<<512, 768>>>()`, i.e 768 threads per block. Each SM would only be able to schedule 2 blocks at a time. I.e `768*2=1536/2048` which is 75% occupancy.

-----

Another case, if a kernel was launched with `testKernel<<<512, 32>>>(), i.e 32 threads per block, then each SM would not run into limit on `maxThreadsPerMultiProcessor`, but `maxBlocksPerMultiProcess` is 32 only. Scheduler will be able to assign 32 blocks. Which is 32*32=1024 threads. 
So `1024/2048` is 50% occupancy. 


